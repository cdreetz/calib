{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import matplotlib.pyplot as plt\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_list(df):\n",
    "    x = df.to_numpy()\n",
    "    li = []\n",
    "    for i in range(x.shape[0]):\n",
    "        li.append([float(j) for j in x[i][0].split(\" \")])\n",
    "    return li\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetprep(n=5):\n",
    "    train_dataset_list = []\n",
    "    train_label_list = []\n",
    "    for i in range(n):\n",
    "        df = pd.read_csv(r'C://Users/Christian/Desktop/calib_challenge/calib_challenge/labeled/' + str(i) + \".txt\",delimiter=\"\\t\",header=None)\n",
    "        label_list = df.values.tolist()\n",
    "        train_label_list += label_list\n",
    "        cap = cv2.VideoCapture(r\"C://Users/Christian/Desktop/calib_challenge/calib_challenge/labeled/\"+str(i)+\".hevc\")\n",
    "        if(cap.isOpened()==False):\n",
    "            print(\"Error Opening the video stream or file\")\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # if frame is read correctly ret is True\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "                break\n",
    "            gray = frame #cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow('frame', gray)\n",
    "            #print((frame.shape))\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "                \n",
    "            train_dataset_list.append(frame)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return train_dataset_list, train_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list, train_label_list = datasetprep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = np.array(train_dataset_list)\n",
    "train_label_list = np.array(train_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_dataset_list[0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 874\n",
    "IMAGE_HEIGHT = 1164\n",
    "IMG_SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "res_net = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 874\n",
    "IMAGE_HEIGHT = 1164\n",
    "IMG_SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "vgg_net = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def ModelCreator(base_model,lr=0.001):\n",
    "    global_average_layer = layers.GlobalAveragePooling2D()\n",
    "\n",
    "    output_layer = layers.Dense(5, activation='relu')\n",
    "\n",
    "    tl_model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        global_average_layer,\n",
    "        layers.BatchNormalization(),\n",
    "        output_layer\n",
    "    ])\n",
    "\n",
    "    tf.keras.optimizers.Adam(\n",
    "        learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "        name='Adam')\n",
    "    tl_model.summary()\n",
    "    tl_model.compile(loss='mean_squared_error', optimizer='Adam', metrics=[\"mean_squared_error\"])\n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(tl_model,X_TRAIN,Y_TRAIN,batch_size=15,epoch=5):\n",
    "    print(\".... Result.....\")\n",
    "    history = tl_model.fit(X_TRAIN,Y_TRAIN,batch_size=batch_size, epochs=epoch, verbose=2, validation_split = 0.50)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_base_models= [vgg_net,res_net]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_models = []\n",
    "learnRate = [0.1,0.01,0.001,0.0001]\n",
    "for i in possible_base_models:\n",
    "    for j in learnRate:\n",
    "        model = ModelCreator(base_model=i,lr=j)\n",
    "        possible_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_dataset = train_dataset_list.flatten()\n",
    "flat_label = train_label_list.flatten()\n",
    "\n",
    "is_string_dataset = np.array([isinstance,(x, str)for x in flat_dataset])\n",
    "is_string_label = np.array([isinstance,(x, str) for x in flat_label])\n",
    "\n",
    "if is_string_dataset():\n",
    "    print('String found', np.where(is_string_dataset))\n",
    "\n",
    "if is_string_label():\n",
    "    print('String found', np.where(is_string_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### pick up here to check whats wrong w the np.array stuff\n",
    "\n",
    "flat_dataset = train_dataset_list.flatten()\n",
    "flat_label = train_label_list.flatten()\n",
    "\n",
    "vfunc = np.vectorize(lambda x: isinstance(x, str))\n",
    "\n",
    "is_string_dataset = vfunc(flat_dataset)\n",
    "is_string_label = vfunc(flat_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in possible_models:\n",
    "    training_model(i,train_dataset_list,train_label_list,batch_size=2,epoch=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
